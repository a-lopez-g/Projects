{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alopez/anaconda3/envs/llm_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-05 11:49:20.467941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-05 11:49:20.481204: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-05 11:49:20.485249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 11:49:20.507335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-05 11:49:21.326424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:43<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "fine_tuned_model = \"andrealopez/Llama-3.1-70B-Instruct-Pima-Diabetes-Clasification\"\n",
    "\n",
    "# base_model = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "# fine_tuned_model = \"andrealopez/Llama-3.1-70B-Instruct-Pima-Diabetes-Clasification\"\n",
    "\n",
    "# Reload tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge adapter with base model\n",
    "model = PeftModel.from_pretrained(base_model_reload, fine_tuned_model)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load and serialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape (154, 9)\n"
     ]
    }
   ],
   "source": [
    "# PIMA\n",
    "test_dataset = pd.read_csv('./PIMA_dataset/test_data.csv')\n",
    "print(\"Test dataset shape\",test_dataset.shape)\n",
    "\n",
    "# Serialize data\n",
    "target_column = \"Outcome\"\n",
    "\n",
    "instruction = f\"\"\"You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. \\nPredict the {target_column} of the next patient.\\n\"\"\"\n",
    "few_shot_instruction = f\"\"\"You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. Here are some examples.\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_data(row):\n",
    "    features_text = \" \".join([\n",
    "        f\"The {col} is {str(row[col])}.\" for col in feature_columns\n",
    "    ])\n",
    "    # PIMA prompt\n",
    "    prompt = f\"\"\"Health values: {features_text}.\n",
    "    Outcome: {int(row[target_column])}.\"\"\".strip()\n",
    "    return prompt\n",
    "\n",
    "def delete_label_value(row): \n",
    "    # PIMA\n",
    "    return re.sub(r'Outcome: \\d.', 'Outcome:', row)\n",
    "\n",
    "def few_shot_prompt(df_shots): \n",
    "    prompt = \"\\n\".join([\n",
    "        row['serialized_row'] for index, row in df_shots.iterrows()\n",
    "    ])\n",
    "    return prompt\n",
    "\n",
    "# Preprocess test dataset\n",
    "feature_columns = [col for col in test_dataset.columns if col != target_column]\n",
    "test_dataset.loc[:,'serialized_row']  = test_dataset.apply(serialize_data, axis=1)\n",
    "\n",
    "\n",
    "# Few shot\n",
    "few_shot = False\n",
    "k_shots = 6\n",
    "if few_shot: \n",
    "    # Shots # TODO: coger las muestras de train o validation\n",
    "    df_shots = test_dataset.sample(n=k_shots, random_state=42)\n",
    "    test_dataset = test_dataset.drop(df_shots.index)\n",
    "    # Few shot prompting\n",
    "    # PIMA prompt\n",
    "    instruction = few_shot_instruction + few_shot_prompt(df_shots) + f\"\\nPredict the {target_column} of the next patient.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. \\nPredict the Outcome of the next patient.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_pima_inference(answer,serialized_instance,row,real_values,output_values):\n",
    "    pattern = rf\"{re.escape(serialized_instance)}\\s*['\\\"]?(\\d)['\\\"]?\"\n",
    "    # Buscar el Outcome predicho\n",
    "    match = re.search(pattern, answer, re.DOTALL)\n",
    "    if match:\n",
    "        predicted_outcome = match.group(1).strip()  # Obtener todo el contenido después y eliminar espacios en blanco\n",
    "        if int(predicted_outcome) not in [0,1]: \n",
    "            print(\"Outcome not in [0,1]: \", predicted_outcome)\n",
    "        else: \n",
    "            output_values.append(int(predicted_outcome))\n",
    "            real_values.append(row.Outcome)\n",
    "            \n",
    "    else:\n",
    "        print(\"Not sample match founded.\")\n",
    "        print(answer)\n",
    "\n",
    "    return real_values,output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. \n",
      "Predict the Outcome of the next patient.\n",
      "Health values: The Pregnancies is 2.0. The Glucose is 100.0. The BloodPressure is 64.0. The SkinThickness is 23.0. The Insulin is 0.0. The BMI is 29.7. The DiabetesPedigreeFunction is 0.368. The Age is 21.0..\n",
      "    Outcome:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. \\nPredict the Outcome of the next patient.\\nHealth values: The Pregnancies is 2.0. The Glucose is 100.0. The BloodPressure is 64.0. The SkinThickness is 23.0. The Insulin is 0.0. The BMI is 29.7. The DiabetesPedigreeFunction is 0.368. The Age is 21.0..\\n    Outcome: '0'. Health values: The Pregnancies is\"}]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m result \u001b[38;5;241m=\u001b[39m pipe(prompt)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     27\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     28\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "real_values = []\n",
    "output_values = []\n",
    "inference_times = []\n",
    "iterations_to_fix = []\n",
    "\n",
    "# Inference pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=10\n",
    ")\n",
    "\n",
    "for i, row in test_dataset.iterrows():\n",
    "    serialized_instance = delete_label_value(row.serialized_row)\n",
    "    # Create prompt\n",
    "    prompt = instruction + serialized_instance\n",
    "\n",
    "    # Clasificate sample\n",
    "    start_time = time.time()\n",
    "    result = pipe(prompt)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    inference_times.append(inference_time)\n",
    "    print(inference_time)\n",
    "\n",
    "    # Answer\n",
    "    answer = result[0]['generated_text'].strip()\n",
    "\n",
    "    # Postprocessing to check that is the outcome of the tample\n",
    "    # PIMA\n",
    "    real_values,output_values = postprocess_pima_inference(answer,serialized_instance,row,real_values,output_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 92, 1: 56})\n",
      "Counter({0: 111, 1: 37})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(real_values))\n",
    "print(Counter(output_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7364864864864865,\n",
       " 'precision': 0.7353299245191136,\n",
       " 'recall': 0.7364864864864865,\n",
       " 'f1_score': 0.7219003526011313,\n",
       " 'base_model': 'meta-llama/Llama-3.1-70B-Instruct',\n",
       " 'finetuned_model': 'andrealopez/Llama-3.1-70B-Instruct-Pima-Diabetes-Clasification',\n",
       " 'few_shot': '6-shot',\n",
       " 'inference_times': [3.483624219894409,\n",
       "  3.4843640327453613,\n",
       "  3.4847230911254883,\n",
       "  3.4863381385803223,\n",
       "  1.8630268573760986,\n",
       "  3.4868431091308594,\n",
       "  3.485675811767578,\n",
       "  3.486767530441284,\n",
       "  3.4875452518463135,\n",
       "  1.8640327453613281,\n",
       "  3.4877076148986816,\n",
       "  1.8646292686462402,\n",
       "  1.864185094833374,\n",
       "  3.485379695892334,\n",
       "  1.8647079467773438,\n",
       "  3.486693859100342,\n",
       "  3.486258029937744,\n",
       "  3.486452341079712,\n",
       "  3.4871459007263184,\n",
       "  1.8628954887390137,\n",
       "  3.4891059398651123,\n",
       "  3.485926866531372,\n",
       "  3.4859085083007812,\n",
       "  3.487027406692505,\n",
       "  3.4878196716308594,\n",
       "  3.487455129623413,\n",
       "  3.4862587451934814,\n",
       "  1.8657164573669434,\n",
       "  3.48938250541687,\n",
       "  3.4877560138702393,\n",
       "  3.4874134063720703,\n",
       "  1.864314079284668,\n",
       "  3.489283323287964,\n",
       "  3.487592935562134,\n",
       "  3.4879751205444336,\n",
       "  3.4866209030151367,\n",
       "  1.8617160320281982,\n",
       "  3.4889113903045654,\n",
       "  3.4864909648895264,\n",
       "  3.4874165058135986,\n",
       "  3.486781358718872,\n",
       "  3.4870011806488037,\n",
       "  3.487569570541382,\n",
       "  1.8638651371002197,\n",
       "  3.486929178237915,\n",
       "  1.865680456161499,\n",
       "  3.487217664718628,\n",
       "  3.4882113933563232,\n",
       "  3.48622727394104,\n",
       "  1.8650634288787842,\n",
       "  1.8626081943511963,\n",
       "  3.488154649734497,\n",
       "  3.4873921871185303,\n",
       "  3.4880104064941406,\n",
       "  3.4889187812805176,\n",
       "  3.4852685928344727,\n",
       "  1.863755702972412,\n",
       "  3.4842770099639893,\n",
       "  3.4879419803619385,\n",
       "  3.4849231243133545,\n",
       "  3.48791241645813,\n",
       "  3.4878835678100586,\n",
       "  3.4868648052215576,\n",
       "  3.4865405559539795,\n",
       "  3.4869372844696045,\n",
       "  3.4881765842437744,\n",
       "  3.487576484680176,\n",
       "  3.4796254634857178,\n",
       "  3.488023042678833,\n",
       "  3.4818835258483887,\n",
       "  3.4934184551239014,\n",
       "  3.5315041542053223,\n",
       "  3.4927103519439697,\n",
       "  3.48886775970459,\n",
       "  3.475332021713257,\n",
       "  3.4830312728881836,\n",
       "  3.4845974445343018,\n",
       "  3.485246419906616,\n",
       "  3.4816434383392334,\n",
       "  3.483494997024536,\n",
       "  3.484837532043457,\n",
       "  3.484577178955078,\n",
       "  1.8604671955108643,\n",
       "  3.4896717071533203,\n",
       "  1.8544013500213623,\n",
       "  3.4885778427124023,\n",
       "  3.4930200576782227,\n",
       "  1.8741271495819092,\n",
       "  3.4880759716033936,\n",
       "  3.4898934364318848,\n",
       "  3.4901716709136963,\n",
       "  3.488635301589966,\n",
       "  3.4905762672424316,\n",
       "  3.493809223175049,\n",
       "  3.4903109073638916,\n",
       "  1.864988088607788,\n",
       "  3.500464677810669,\n",
       "  3.4984920024871826,\n",
       "  3.481417655944824,\n",
       "  3.493408441543579,\n",
       "  3.4935178756713867,\n",
       "  3.488286018371582,\n",
       "  3.487534761428833,\n",
       "  3.486741542816162,\n",
       "  3.4846384525299072,\n",
       "  3.4901914596557617,\n",
       "  3.4897706508636475,\n",
       "  1.859870195388794,\n",
       "  3.486733913421631,\n",
       "  3.4853127002716064,\n",
       "  3.4852750301361084,\n",
       "  3.4847521781921387,\n",
       "  3.483809471130371,\n",
       "  3.485281229019165,\n",
       "  3.484300136566162,\n",
       "  3.4819681644439697,\n",
       "  3.48288893699646,\n",
       "  1.8599193096160889,\n",
       "  3.494513511657715,\n",
       "  3.48533296585083,\n",
       "  3.4829630851745605,\n",
       "  3.4843313694000244,\n",
       "  3.4836642742156982,\n",
       "  3.482560634613037,\n",
       "  3.4839799404144287,\n",
       "  1.8594403266906738,\n",
       "  3.4859213829040527,\n",
       "  3.487227439880371,\n",
       "  3.4846575260162354,\n",
       "  3.482985734939575,\n",
       "  3.484678268432617,\n",
       "  3.487581253051758,\n",
       "  3.483815908432007,\n",
       "  3.483686685562134,\n",
       "  3.482576608657837,\n",
       "  3.4858834743499756,\n",
       "  1.8612339496612549,\n",
       "  1.8633391857147217,\n",
       "  3.4999194145202637,\n",
       "  3.496241807937622,\n",
       "  1.863095998764038,\n",
       "  1.856485366821289,\n",
       "  3.483536958694458,\n",
       "  3.483525037765503,\n",
       "  3.4761717319488525,\n",
       "  3.4785890579223633,\n",
       "  3.480215549468994,\n",
       "  3.4734041690826416],\n",
       " 'instruction': \"You are a doctor specialised in classifying patients as diabetic or non-diabetic based on their health values. Instruction: Respond only with '0' for non-diabetic or '1' for diabetic. Use the following output format: 'Outcome: 0'. Here are some examples.\\nHealth values: The Pregnancies is 0.0. The Glucose is 137.0. The BloodPressure is 70.0. The SkinThickness is 38.0. The Insulin is 0.0. The BMI is 33.2. The DiabetesPedigreeFunction is 0.17. The Age is 22.0..\\n    Outcome: 0.\\nHealth values: The Pregnancies is 8.0. The Glucose is 197.0. The BloodPressure is 74.0. The SkinThickness is 0.0. The Insulin is 0.0. The BMI is 25.9. The DiabetesPedigreeFunction is 1.191. The Age is 39.0..\\n    Outcome: 1.\\nHealth values: The Pregnancies is 1.0. The Glucose is 109.0. The BloodPressure is 60.0. The SkinThickness is 8.0. The Insulin is 182.0. The BMI is 25.4. The DiabetesPedigreeFunction is 0.947. The Age is 21.0..\\n    Outcome: 0.\\nHealth values: The Pregnancies is 7.0. The Glucose is 136.0. The BloodPressure is 90.0. The SkinThickness is 0.0. The Insulin is 0.0. The BMI is 29.9. The DiabetesPedigreeFunction is 0.21. The Age is 50.0..\\n    Outcome: 0.\\nHealth values: The Pregnancies is 1.0. The Glucose is 135.0. The BloodPressure is 54.0. The SkinThickness is 0.0. The Insulin is 0.0. The BMI is 26.7. The DiabetesPedigreeFunction is 0.687. The Age is 62.0..\\n    Outcome: 0.\\nHealth values: The Pregnancies is 1.0. The Glucose is 97.0. The BloodPressure is 68.0. The SkinThickness is 21.0. The Insulin is 0.0. The BMI is 27.2. The DiabetesPedigreeFunction is 1.095. The Age is 22.0..\\n    Outcome: 0.\\nPredict the Outcome of the next patient.\\n\",\n",
       " 'dataset': 'PIMA',\n",
       " 'train_size': 491,\n",
       " 'validation_size': 123,\n",
       " 'test_size': 148}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def inference_results(real_values, predicted_values,base_model,new_model,inference_times,test_dataset, instruction):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(real_values, predicted_values),\n",
    "        \"precision\": precision_score(real_values, predicted_values, average='weighted'),\n",
    "        \"recall\": recall_score(real_values, predicted_values, average='weighted'),\n",
    "        \"f1_score\": f1_score(real_values, predicted_values, average='weighted'),\n",
    "        \"base_model\": base_model,\n",
    "        \"finetuned_model\": new_model,\n",
    "        \"few_shot\": \"6-shot\",\n",
    "        \"inference_times\" : inference_times,\n",
    "        \"instruction\":instruction,\n",
    "        \"dataset\": \"PIMA\",\n",
    "        \"train_size\": 491,\n",
    "        \"validation_size\": 123,\n",
    "        \"test_size\" : len(test_dataset),\n",
    "        \n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "results = inference_results(real_values, output_values,base_model,fine_tuned_model,inference_times,test_dataset,instruction)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./PIMA_dataset/inference_metrics_llama3.1_70B_6shot_4_11_2024.json', 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
