{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alopez/anaconda3/envs/r_env/lib/python3.11/site-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/alopez/anaconda3/envs/r_env/lib/python3.11/site-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/alopez/anaconda3/envs/r_env/lib/python3.11/site-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import umap\n",
    "import umap.plot\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy.external as sce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (filter): (10101, 32738) cells x genes\n",
      "Data loaded (filter + normalized ): (10101, 32738) cells x genes\n",
      "Data loaded (filter + normalized + scaled ): (10101, 32738) cells x genes\n"
     ]
    }
   ],
   "source": [
    "# Withou Feature Selection\n",
    "# Filtered data\n",
    "filtered_data = anndata.read_h5ad(\"./data/filtered_data.h5ad.gz\")\n",
    "print(f\"Data loaded (filter): {filtered_data.shape} cells x genes\")\n",
    "# Filtered and normalized data\n",
    "normalized_data = anndata.read_h5ad(\"./data/filtered_normalized_data.h5ad.gz\")\n",
    "print(f\"Data loaded (filter + normalized ): {normalized_data.shape} cells x genes\")\n",
    "# Filtered + normalized + scaled data\n",
    "scaled_data = anndata.read_h5ad(\"./data/scaled_data.h5ad.gz\")\n",
    "print(f\"Data loaded (filter + normalized + scaled ): {scaled_data.shape} cells x genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (Filtered + HVG): (10101, 919) cells x genes\n",
      "Data loaded (Filtered + HVG + ZScore): (10101, 919) cells x genes\n"
     ]
    }
   ],
   "source": [
    "# Load AnnData objects\n",
    "HVG_data = anndata.read_h5ad(\"./data/HVG_data.h5ad.gz\")\n",
    "print(f\"Data loaded (Filtered + HVG): {HVG_data.shape} cells x genes\")\n",
    "pcHVG_data = anndata.read_h5ad(\"./data/pcHVG_data.h5ad.gz\")\n",
    "print(f\"Data loaded (Filtered + HVG + ZScore): {pcHVG_data.shape} cells x genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Batch effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Variation in single-cell and spatial RNA sequencing data is known to be influenced by technical factors. In some cases, these technical factors may confound our ability to measure true biological variation between samples, making it more challenging to address the research question at hand.\n",
    "\n",
    "Cause: These confounding factors include experimental biases and batch effects. Unavoidable systematic technical biases can include unequal amplification during PCR, cell lysis, reverse transcriptase enzyme efficiency, and stochastic molecular sampling during sequencing. By contrast, batch effects are technical, non-biological factors that also affect variation in the resulting data, but they occur in batches of samples. A “batch” refers to an individual group of samples that are processed differently relative to other samples in the experiment.\n",
    "\n",
    "Solution: Technical factors that potentially lead to batch effects may be avoided with mitigation strategies in the lab and during sequencing. Examples of lab strategies include: sampling cells on the same day, using the same handling personnel, reagent lots, protocols, reducing PCR amplification bias, and generally using the same equipment. Sequencing strategies can include multiplexing libraries across flow cells. For example, if samples came from two patients, pooling libraries together and spreading them across flow cells can potentially spread out the flow cell-specific variation across samples.\n",
    "\n",
    "Computational batch correction aims to remove technical variation from the data preventing this variation from confounding downstream analysis. There are several batch correction methods and tools that have implemented them.\n",
    "\n",
    "Methods: \n",
    "\n",
    " * https://www.10xgenomics.com/analysis-guides/introduction-batch-effect-correction\n",
    " * Harmony: https://doi.org/10.1038%2Fs41592-019-0619-0\n",
    " * BBKNN: https://doi.org/10.1093/bioinformatics/btz625\n",
    " * Scanorama: \n",
    " * LIGER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large single-cell RNA sequencing (scRNA-seq) projects usually need to generate data across multiple batches due to logistical constraints. However, the processing of different batches is often subject to uncontrollable differences, e.g., changes in operator, differences in reagent quality. This results in systematic differences in the observed expression in cells from different batches, which we refer to as “batch effects”. Batch effects are problematic as they can be major drivers of heterogeneity in the data, masking the relevant biological differences and complicating interpretation of the results.\n",
    "\n",
    "\n",
    "Normalization occurs regardless of the batch structure and only considers technical biases, while batch correction - as the name suggests - only occurs across batches and must consider both technical biases and biological differences. Technical biases tend to affect genes in a similar manner, or at least in a manner related to their biophysical properties (e.g., length, GC content), while biological differences between batches can be highly unpredictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Harmony, BBKNN and Scanorama need PCA\n",
    "# Without Z-Score\n",
    "sc.tl.pca(HVG_data, n_comps=50, svd_solver='randomized')\n",
    "# With Z-Score\n",
    "sc.tl.pca(pcHVG_data, n_comps=50, svd_solver='randomized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(filtered_data, n_comps=50, svd_solver='randomized')\n",
    "sc.tl.pca(normalized_data, n_comps=50, svd_solver='randomized')\n",
    "sc.tl.pca(scaled_data, n_comps=50, svd_solver='randomized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 17:32:53,673 - harmonypy - INFO - Computing initial centroids with sklearn.KMeans...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 17:32:55,866 - harmonypy - INFO - sklearn.KMeans initialization complete.\n",
      "2024-07-04 17:32:55,922 - harmonypy - INFO - Iteration 1 of 10\n",
      "2024-07-04 17:32:57,800 - harmonypy - INFO - Iteration 2 of 10\n",
      "2024-07-04 17:32:59,755 - harmonypy - INFO - Converged after 2 iterations\n"
     ]
    }
   ],
   "source": [
    "# Without ZScore ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "HVG_data_harmony = HVG_data.copy()\n",
    "sce.pp.harmony_integrate(HVG_data_harmony,\"reprogramming_type\")\n",
    "# Save Harmony PCA in X_pca\n",
    "HVG_data_harmony.obsm['X_pca'] = HVG_data_harmony.obsm['X_pca_harmony']\n",
    "\n",
    "HVG_data_harmony.write_h5ad(\"./data/batch_effect/Harmony_HVG_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 17:33:01,674 - harmonypy - INFO - Computing initial centroids with sklearn.KMeans...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 17:33:03,673 - harmonypy - INFO - sklearn.KMeans initialization complete.\n",
      "2024-07-04 17:33:03,736 - harmonypy - INFO - Iteration 1 of 10\n",
      "2024-07-04 17:33:05,673 - harmonypy - INFO - Iteration 2 of 10\n",
      "2024-07-04 17:33:07,503 - harmonypy - INFO - Converged after 2 iterations\n"
     ]
    }
   ],
   "source": [
    "# With ZScore ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "pcHVG_data_harmony = pcHVG_data.copy()\n",
    "sce.pp.harmony_integrate(pcHVG_data_harmony,\"reprogramming_type\")\n",
    "pcHVG_data_harmony.obsm['X_pca'] = pcHVG_data_harmony.obsm['X_pca_harmony']\n",
    "\n",
    "pcHVG_data_harmony.write_h5ad(\"./data/batch_effect/Harmony_pcHVG_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 16:55:42,507 - harmonypy - INFO - Computing initial centroids with sklearn.KMeans...\n",
      "2024-07-11 16:55:44,600 - harmonypy - INFO - sklearn.KMeans initialization complete.\n",
      "2024-07-11 16:55:44,658 - harmonypy - INFO - Iteration 1 of 10\n",
      "2024-07-11 16:55:46,484 - harmonypy - INFO - Iteration 2 of 10\n",
      "2024-07-11 16:55:48,308 - harmonypy - INFO - Iteration 3 of 10\n",
      "2024-07-11 16:55:50,133 - harmonypy - INFO - Converged after 3 iterations\n",
      "2024-07-11 16:56:00,451 - harmonypy - INFO - Computing initial centroids with sklearn.KMeans...\n",
      "2024-07-11 16:56:02,628 - harmonypy - INFO - sklearn.KMeans initialization complete.\n",
      "2024-07-11 16:56:02,683 - harmonypy - INFO - Iteration 1 of 10\n",
      "2024-07-11 16:56:04,595 - harmonypy - INFO - Iteration 2 of 10\n",
      "2024-07-11 16:56:06,518 - harmonypy - INFO - Converged after 2 iterations\n",
      "2024-07-11 16:56:16,628 - harmonypy - INFO - Computing initial centroids with sklearn.KMeans...\n",
      "2024-07-11 16:56:18,698 - harmonypy - INFO - sklearn.KMeans initialization complete.\n",
      "2024-07-11 16:56:18,765 - harmonypy - INFO - Iteration 1 of 10\n",
      "2024-07-11 16:56:20,632 - harmonypy - INFO - Iteration 2 of 10\n",
      "2024-07-11 16:56:22,517 - harmonypy - INFO - Converged after 2 iterations\n"
     ]
    }
   ],
   "source": [
    "# Without Feature Selection ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "filtered_data_harmony = filtered_data.copy()\n",
    "sce.pp.harmony_integrate(filtered_data_harmony,\"reprogramming_type\")\n",
    "filtered_data_harmony.obsm['X_pca'] = filtered_data_harmony.obsm['X_pca_harmony']\n",
    "filtered_data_harmony.write_h5ad(\"./data/batch_effect/Harmony_filtered_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "normalized_data_harmony = normalized_data.copy()\n",
    "sce.pp.harmony_integrate(normalized_data_harmony,\"reprogramming_type\")\n",
    "normalized_data_harmony.obsm['X_pca'] = normalized_data_harmony.obsm['X_pca_harmony']\n",
    "normalized_data_harmony.write_h5ad(\"./data/batch_effect/Harmony_normalized_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "scaled_data_harmony = scaled_data.copy()\n",
    "sce.pp.harmony_integrate(scaled_data_harmony,\"reprogramming_type\")\n",
    "scaled_data_harmony.obsm['X_pca'] = scaled_data_harmony.obsm['X_pca_harmony']\n",
    "scaled_data_harmony.write_h5ad(\"./data/batch_effect/Harmony_scaled_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 BBKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: consider updating your call to make use of `computation`\n"
     ]
    }
   ],
   "source": [
    "# Without Z-Score\n",
    "HVG_data_BBKNN = HVG_data.copy()\n",
    "sc.external.pp.bbknn(HVG_data_BBKNN, batch_key=\"reprogramming_type\")  # running bbknn 1.3.6\n",
    "HVG_data_BBKNN.write_h5ad(\"./data/batch_effect/BBKNN_HVG.h5ad_data.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: consider updating your call to make use of `computation`\n"
     ]
    }
   ],
   "source": [
    "# With Z-Score\n",
    "pcHVG_data_BBKNN = pcHVG_data.copy()\n",
    "sc.external.pp.bbknn(pcHVG_data_BBKNN, batch_key=\"reprogramming_type\")  # running bbknn 1.3.6\n",
    "pcHVG_data_BBKNN.write_h5ad(\"./data/batch_effect/BBKNN_pcHVG_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: consider updating your call to make use of `computation`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145040/1143968102.py:5: FutureWarning: The specified parameters ('batch_key',) are no longer positional. Please specify them like `batch_key='reprogramming_type'`\n",
      "  sc.external.pp.bbknn(filtered_data_BBKNN,\"reprogramming_type\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: consider updating your call to make use of `computation`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145040/1143968102.py:10: FutureWarning: The specified parameters ('batch_key',) are no longer positional. Please specify them like `batch_key='reprogramming_type'`\n",
      "  sc.external.pp.bbknn(normalized_data_BBKNN,\"reprogramming_type\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: consider updating your call to make use of `computation`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145040/1143968102.py:15: FutureWarning: The specified parameters ('batch_key',) are no longer positional. Please specify them like `batch_key='reprogramming_type'`\n",
      "  sc.external.pp.bbknn(scaled_data_BBKNN,\"reprogramming_type\")\n"
     ]
    }
   ],
   "source": [
    "# Without Feature Selection ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "filtered_data_BBKNN = filtered_data.copy()\n",
    "sc.external.pp.bbknn(filtered_data_BBKNN,\"reprogramming_type\")\n",
    "filtered_data_BBKNN.write_h5ad(\"./data/batch_effect/BBKNN_filtered_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "normalized_data_BBKNN = normalized_data.copy()\n",
    "sc.external.pp.bbknn(normalized_data_BBKNN,\"reprogramming_type\")\n",
    "normalized_data_BBKNN.write_h5ad(\"./data/batch_effect/BBKNN_normalized_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "scaled_data_BBKNN = scaled_data.copy()\n",
    "sc.external.pp.bbknn(scaled_data_BBKNN,\"reprogramming_type\")\n",
    "scaled_data_BBKNN.write_h5ad(\"./data/batch_effect/BBKNN_scaled_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Scanorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nature.com/articles/s41587-019-0113-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.15580789]\n",
      " [0.         0.        ]]\n",
      "Processing datasets False <=> chemical reprogramming\n"
     ]
    }
   ],
   "source": [
    "# Without Z-Score \n",
    "HVG_data_Scanorama = HVG_data.copy()\n",
    "sce.pp.scanorama_integrate(HVG_data_Scanorama,\"reprogramming_type\") \n",
    "HVG_data_Scanorama.write_h5ad(\"./data/batch_effect/Scanorama_HVG_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.14408042]\n",
      " [0.         0.        ]]\n",
      "Processing datasets False <=> chemical reprogramming\n"
     ]
    }
   ],
   "source": [
    "# With Z-Score\n",
    "pcHVG_data_Scanorama= pcHVG_data.copy()\n",
    "sce.pp.scanorama_integrate(pcHVG_data_Scanorama,\"reprogramming_type\") \n",
    "pcHVG_data_Scanorama.write_h5ad(\"./data/batch_effect/Scanorama_pcHVG_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.11634401]\n",
      " [0.         0.        ]]\n",
      "Processing datasets False <=> chemical reprogramming\n",
      "[[0.         0.15096798]\n",
      " [0.         0.        ]]\n",
      "Processing datasets False <=> chemical reprogramming\n",
      "[[0.         0.17572599]\n",
      " [0.         0.        ]]\n",
      "Processing datasets False <=> chemical reprogramming\n"
     ]
    }
   ],
   "source": [
    "# Without Feature Selection ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "filtered_data_Scanorama = filtered_data.copy()\n",
    "sce.pp.scanorama_integrate(filtered_data_Scanorama,\"reprogramming_type\")\n",
    "filtered_data_BBKNN.write_h5ad(\"./data/batch_effect/Scanorama_filtered_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "normalized_data_Scanorama = normalized_data.copy()\n",
    "sce.pp.scanorama_integrate(normalized_data_Scanorama,\"reprogramming_type\")\n",
    "normalized_data_Scanorama.write_h5ad(\"./data/batch_effect/Scanorama_normalized_data.h5ad.gz\", compression=\"gzip\")\n",
    "\n",
    "# Reprogramming type is the key to differentiate between experiments\n",
    "scaled_data_Scanorama = scaled_data.copy()\n",
    "sce.pp.scanorama_integrate(scaled_data_Scanorama,\"reprogramming_type\")\n",
    "scaled_data_Scanorama.write_h5ad(\"./data/batch_effect/Scanorama_scaled_data.h5ad.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 LIGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CON O SIN PCA ANTES? \n",
    "# integrative non-negative matrix factorization on the normalized and scaled datasets\n",
    "# los datos pueden estar limpios, con los genes seleccionados y normalizado pero no centrados -> HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyliger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a probar con los datos originales para tener otra aproximación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_id\n",
      "gene_name\n",
      "cell_id\n",
      "gene_name\n",
      "Index(['AAACCCAAGAAGAGCA-1', 'AAACCCACAAAGTGTA-1', 'AAACCCACACTGTCCT-1',\n",
      "       'AAACCCAGTCGACTTA-1', 'AAACCCAGTGGTCTTA-1', 'AAACCCATCAGCCTTC-1',\n",
      "       'AAACGAAAGAGAACCC-1', 'AAACGAAAGCTTACGT-1', 'AAACGAACAATGAAAC-1',\n",
      "       'AAACGAAGTCCGTTTC-1',\n",
      "       ...\n",
      "       'TTTGGTTCATTAAAGG-1', 'TTTGGTTGTCTTTCAT-1', 'TTTGGTTTCAAGCCGC-1',\n",
      "       'TTTGGTTTCTCTTAAC-1', 'TTTGTTGCATCTCAAG-1', 'TTTGTTGGTATCAGGG-1',\n",
      "       'TTTGTTGGTATGCAAA-1', 'TTTGTTGTCATTGCGA-1', 'TTTGTTGTCCCGTTGT-1',\n",
      "       'TTTGTTGTCGACGTCG-1'],\n",
      "      dtype='object', name='cell_id', length=5372)\n",
      "Index(['ISG15', 'RNF207', 'CTNNBIP1', 'DHRS3', 'KAZN', 'EFHD2', 'FBLIM1',\n",
      "       'AKR7A2', 'NBL1', 'CAMK2N1',\n",
      "       ...\n",
      "       'PAXBP1', 'ETS2', 'HMGN1', 'COL18A1', 'COL6A2', 'MT-CO1', 'MT-ATP6',\n",
      "       'MT-CO3', 'MT-ND4L', 'MT-CYB'],\n",
      "      dtype='object', name='gene_name', length=919)\n",
      "Index(['AAACCCAAGTCACGAG-1', 'AAACCCATCTAGATCG-1', 'AAACGAAAGCTGACAG-1',\n",
      "       'AAACGAAAGTCCTACA-1', 'AAACGAACATATCTCT-1', 'AAACGAAGTAAGTTAG-1',\n",
      "       'AAACGAAGTCTACAGT-1', 'AAACGAATCACTGATG-1', 'AAACGAATCGGTAGGA-1',\n",
      "       'AAACGCTAGCTGAAGC-1',\n",
      "       ...\n",
      "       'TTTGGTTGTTCACGAT-1', 'TTTGGTTGTTCATCTT-1', 'TTTGGTTGTTGCATAC-1',\n",
      "       'TTTGTTGAGCTGTTAC-1', 'TTTGTTGCACAGGATG-1', 'TTTGTTGCATTGTCGA-1',\n",
      "       'TTTGTTGGTCTGCAAT-1', 'TTTGTTGGTGAATGAT-1', 'TTTGTTGGTTTGTTCT-1',\n",
      "       'TTTGTTGTCGTGCACG-1'],\n",
      "      dtype='object', name='cell_id', length=4729)\n",
      "Index(['ISG15', 'RNF207', 'CTNNBIP1', 'DHRS3', 'KAZN', 'EFHD2', 'FBLIM1',\n",
      "       'AKR7A2', 'NBL1', 'CAMK2N1',\n",
      "       ...\n",
      "       'PAXBP1', 'ETS2', 'HMGN1', 'COL18A1', 'COL6A2', 'MT-CO1', 'MT-ATP6',\n",
      "       'MT-CO3', 'MT-ND4L', 'MT-CYB'],\n",
      "      dtype='object', name='gene_name', length=919)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2458894/1471175330.py:7: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "/tmp/ipykernel_2458894/1471175330.py:10: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n"
     ]
    }
   ],
   "source": [
    "# Dividimos el objeto de AnnData en dos, uno por cada experimento\n",
    "HVG_data_1 = HVG_data[HVG_data.obs.cell_state == \"somatic\", :]\n",
    "HVG_data_2 = HVG_data[HVG_data.obs.cell_state == \"intermediate plastic state with a regeneration-like program\", :]\n",
    "\n",
    "# Check de que en uns tenemos \"sample_name\" que identifica el experimento -> HVG_data.obs[\"cell_state\"]\n",
    "HVG_data_1.uns.keys()\n",
    "HVG_data_1.uns[\"sample_name\"] = \"somatic\"\n",
    "\n",
    "HVG_data_2.uns.keys()\n",
    "HVG_data_2.uns[\"sample_name\"] = \"chemical_reprogramming\"\n",
    "\n",
    "# Check de nombre de columnas y filas\n",
    "print(HVG_data_1.obs.index.name)\n",
    "HVG_data_1.var.index.name = \"gene_name\"\n",
    "print(HVG_data_1.var.index.name)\n",
    "\n",
    "print(HVG_data_2.obs.index.name)\n",
    "HVG_data_2.var.index.name = \"gene_name\"\n",
    "print(HVG_data_2.var.index.name)\n",
    "\n",
    "# Check nombre de genes y células\n",
    "print(HVG_data_1.obs_names)\n",
    "print(HVG_data_1.var_names)\n",
    "\n",
    "print(HVG_data_2.obs_names)\n",
    "print(HVG_data_2.var_names)\n",
    "\n",
    "# Check de que los identificadores son únicos\n",
    "print(HVG_data_1.obs_names.duplicated().any())\n",
    "print(HVG_data_1.var_names.duplicated().any())\n",
    "\n",
    "print(HVG_data_2.obs_names.duplicated().any())\n",
    "print(HVG_data_2.var_names.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 234 genes not expressing in somatic.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Liger' object has no attribute 'var_genes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m ifnb_liger \u001b[38;5;241m=\u001b[39m pyliger\u001b[38;5;241m.\u001b[39mcreate_liger(adata_list)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Done\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pyliger.normalize(ifnb_liger)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m## TODO: probar qué genes selecciona con todos los datos\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Joint Matrix Factorization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pyliger\u001b[38;5;241m.\u001b[39moptimize_ALS(ifnb_liger, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/r_env/lib/python3.11/site-packages/pyliger/factorization/_iNMF_ANLS.py:82\u001b[0m, in \u001b[0;36moptimize_ALS\u001b[0;34m(liger_object, k, value_lambda, thresh, max_iters, nrep, H_init, W_init, V_init, rand_seed, print_obj)\u001b[0m\n\u001b[1;32m     78\u001b[0m N \u001b[38;5;241m=\u001b[39m liger_object\u001b[38;5;241m.\u001b[39mnum_samples  \u001b[38;5;66;03m# number of total input hdf5 files\u001b[39;00m\n\u001b[1;32m     79\u001b[0m ns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     80\u001b[0m     adata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m adata \u001b[38;5;129;01min\u001b[39;00m liger_object\u001b[38;5;241m.\u001b[39madata_list\n\u001b[1;32m     81\u001b[0m ]  \u001b[38;5;66;03m# number of cells in each hdf5 files\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m num_genes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(liger_object\u001b[38;5;241m.\u001b[39mvar_genes)  \u001b[38;5;66;03m# number of variable genes\u001b[39;00m\n\u001b[1;32m     83\u001b[0m X \u001b[38;5;241m=\u001b[39m [adata\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mfor\u001b[39;00m adata \u001b[38;5;129;01min\u001b[39;00m liger_object\u001b[38;5;241m.\u001b[39madata_list]\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(ns):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Liger' object has no attribute 'var_genes'"
     ]
    }
   ],
   "source": [
    "# Preprocessing and Normalization\n",
    "adata_list = [HVG_data_1,HVG_data_2]\n",
    "ifnb_liger = pyliger.create_liger(adata_list)\n",
    "\n",
    "pyliger.normalize(ifnb_liger)\n",
    "pyliger.select_genes(ifnb_liger)\n",
    "pyliger.scale_not_center(ifnb_liger)\n",
    "\n",
    "# Joint Matrix Factorization\n",
    "pyliger.optimize_ALS(ifnb_liger, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLiger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLiger\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convertir el objeto AnnData a un DataFrame de pandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLiger'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convertir el objeto AnnData a un DataFrame de pandas\n",
    "df_data = HVG_data_LIGER.to_df()\n",
    "\n",
    "# Crear un objeto LIGER\n",
    "liger = pyLiger.create_liger(df_data)\n",
    "\n",
    "# Normalizar los datos\n",
    "# liger.normalize()\n",
    "# Identificar los genes variables\n",
    "# liger.select_genes()\n",
    "# Escalar los datos\n",
    "# liger.scale()\n",
    "# Realizar la factorización de matrices no negativa (NMF)\n",
    "# liger.optimize_nmf(k=20)  # Aquí k es el número de factores latentes\n",
    "\n",
    "# Integrar los datos usando los factores compartidos\n",
    "liger.quantile_norm()\n",
    "\n",
    "# Obtener las representaciones integradas\n",
    "integrated_data = liger.get_expression_matrix()\n",
    "\n",
    "# Visualizar los resultados\n",
    "# Usamos PCA para reducir a 2D para visualización\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(integrated_data.T)\n",
    "\n",
    "# Crear etiquetas de lote para visualización\n",
    "# labels = ['Batch 1'] * data1.shape[0] + ['Batch 2'] * data2.shape[0]\n",
    "\n",
    "# Convertir a un DataFrame para visualización\n",
    "# pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "# pca_df['Batch'] = labels\n",
    "\n",
    "# Visualizar los datos integrados\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label in np.unique(labels):\n",
    "#     plt.scatter(pca_df[pca_df['Batch'] == label]['PC1'],\n",
    "#                 pca_df[pca_df['Batch'] == label]['PC2'],\n",
    "#                 label=label, s=10)\n",
    "# plt.title('LIGER Integrated Data')\n",
    "# plt.legend()\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotInstalledError",
     "evalue": "The R package \"liger\" is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPackageNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m pandas2ri\u001b[38;5;241m.\u001b[39mactivate()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Importar liger en R\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m liger \u001b[38;5;241m=\u001b[39m importr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliger\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convertir el DataFrame de pandas a un DataFrame de R\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m localconverter(ro\u001b[38;5;241m.\u001b[39mdefault_converter \u001b[38;5;241m+\u001b[39m pandas2ri\u001b[38;5;241m.\u001b[39mconverter):\n",
      "File \u001b[0;32m~/anaconda3/envs/r_env/lib/python3.11/site-packages/rpy2/robjects/packages.py:472\u001b[0m, in \u001b[0;36mimportr\u001b[0;34m(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_resolve, data)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Import an R package.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isinstalled(name, lib_loc\u001b[38;5;241m=\u001b[39mlib_loc):\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotInstalledError(\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe R package \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not installed.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name\n\u001b[1;32m    474\u001b[0m     )\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suppress_messages:\n\u001b[1;32m    477\u001b[0m     ok \u001b[38;5;241m=\u001b[39m quiet_require(name, lib_loc\u001b[38;5;241m=\u001b[39mlib_loc)\n",
      "\u001b[0;31mPackageNotInstalledError\u001b[0m: The R package \"liger\" is not installed."
     ]
    }
   ],
   "source": [
    "# Instalar paquetes\n",
    "# install.packages('BiocManager')\n",
    "# BiocManager::install('ronammar/liger', dependencies=TRUE)\n",
    "\n",
    "# Convertir el objeto AnnData a un DataFrame de pandas\n",
    "df_data = HVG_data.to_df()\n",
    "\n",
    "# Activar la conversión automática entre pandas y R\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Importar liger en R\n",
    "liger = importr('liger')\n",
    "\n",
    "# Convertir el DataFrame de pandas a un DataFrame de R\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    r_data = ro.conversion.py2rpy(df_data)\n",
    "\n",
    "# Crear un objeto liger en R\n",
    "ro.globalenv['r_data'] = r_data\n",
    "ro.r('liger_object <- createLiger(list(batch1 = r_data))')\n",
    "\n",
    "# Normalización y escalado de datos\n",
    "ro.r('liger_object <- normalize(liger_object)')\n",
    "ro.r('liger_object <- scaleNotCenter(liger_object)')\n",
    "\n",
    "# Realizar la integración con liger\n",
    "ro.r('liger_object <- optimizeALS(liger_object, k = 20)')\n",
    "ro.r('liger_object <- quantileAlignSNF(liger_object)')\n",
    "\n",
    "# Obtener los resultados de la integración\n",
    "ro.r('integrated_matrix <- liger_object@H.norm')\n",
    "\n",
    "# Convertir la matriz integrada de R a pandas\n",
    "integrated_matrix = ro.conversion.rpy2py(ro.r('integrated_matrix'))\n",
    "\n",
    "# Crear un nuevo objeto AnnData con la matriz integrada\n",
    "adata_integrated = anndata.AnnData(X=integrated_matrix)\n",
    "\n",
    "# Guardar el objeto AnnData integrado\n",
    "adata_integrated.write('integrated_anndata.h5ad')\n",
    "\n",
    "print(\"Integración con LIGER completada y guardada en 'integrated_anndata.h5ad'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
